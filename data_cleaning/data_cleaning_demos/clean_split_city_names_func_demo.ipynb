{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test function to clean & un-split city names data, from the scraped rental listings CSV files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports-- file processing\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# data analysis libraries & SQL libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# SQL ODBC for API connection between Python & SQL Server\n",
    "import pyodbc\n",
    "import sqlalchemy as sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18645 entries, 0 to 18644\n",
      "Data columns (total 48 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   listing_urls             18645 non-null  object \n",
      " 1   ids                      17236 non-null  float64\n",
      " 2   sqft                     13209 non-null  float64\n",
      " 3   cities                   17219 non-null  object \n",
      " 4   prices                   17227 non-null  object \n",
      " 5   bedrooms                 17184 non-null  float64\n",
      " 6   bathrooms                17184 non-null  object \n",
      " 7   attr_vars                17220 non-null  object \n",
      " 8   listing_descrip          17220 non-null  object \n",
      " 9   date_of_webcrawler       17236 non-null  object \n",
      " 10  kitchen                  17220 non-null  float64\n",
      " 11  date_posted              17220 non-null  object \n",
      " 12  region                   18645 non-null  object \n",
      " 13  sub_region               18645 non-null  object \n",
      " 14  cats_OK                  18645 non-null  int64  \n",
      " 15  dogs_OK                  18645 non-null  int64  \n",
      " 16  wheelchair_accessible    18645 non-null  int64  \n",
      " 17  laundry_in_bldg          18645 non-null  int64  \n",
      " 18  no_laundry               18645 non-null  int64  \n",
      " 19  washer_and_dryer         18645 non-null  int64  \n",
      " 20  washer_and_dryer_hookup  18645 non-null  int64  \n",
      " 21  laundry_on_site          18645 non-null  int64  \n",
      " 22  full_kitchen             18645 non-null  int64  \n",
      " 23  dishwasher               18645 non-null  int64  \n",
      " 24  refrigerator             18645 non-null  int64  \n",
      " 25  oven                     18645 non-null  int64  \n",
      " 26  flooring_carpet          18645 non-null  int64  \n",
      " 27  flooring_wood            18645 non-null  int64  \n",
      " 28  flooring_tile            18645 non-null  int64  \n",
      " 29  flooring_hardwood        18645 non-null  int64  \n",
      " 30  flooring_other           18645 non-null  int64  \n",
      " 31  apt_type                 18645 non-null  int64  \n",
      " 32  in_law_apt_type          18645 non-null  int64  \n",
      " 33  condo_type               18645 non-null  int64  \n",
      " 34  townhouse_type           18645 non-null  int64  \n",
      " 35  cottage_or_cabin_type    18645 non-null  int64  \n",
      " 36  single_fam_type          18645 non-null  int64  \n",
      " 37  duplex_type              18645 non-null  int64  \n",
      " 38  is_furnished             18645 non-null  int64  \n",
      " 39  attached_garage          18645 non-null  int64  \n",
      " 40  detached_garage          18645 non-null  int64  \n",
      " 41  carport                  18645 non-null  int64  \n",
      " 42  off_street_parking       18645 non-null  int64  \n",
      " 43  no_parking               18645 non-null  int64  \n",
      " 44  EV_charging              18645 non-null  int64  \n",
      " 45  air_condition            18645 non-null  int64  \n",
      " 46  no_smoking               18645 non-null  int64  \n",
      " 47  Unnamed: 0               535 non-null    float64\n",
      "dtypes: float64(5), int64(33), object(10)\n",
      "memory usage: 6.1+ MB\n"
     ]
    }
   ],
   "source": [
    "def recursively_import_all_CSV_and_concat_to_single_df(parent_direc, fn_regex=r'*.csv'):\n",
    "    \"\"\"Recursively search parent directory, and look up all CSV files.\n",
    "    Then, import all CSV files to a single Pandas' df using pd.concat()\"\"\"\n",
    "    path =  parent_direc # specify parent path of directories containing the scraped rental listings CSV data -- NB: use raw text--as in r'path...', or can we use the double-back slashes to escape back-slashes??\n",
    "    df_concat = pd.concat((pd.read_csv(file) for file in glob.iglob(\n",
    "        os.path.join(path, '**', fn_regex), \n",
    "        recursive=True)), ignore_index=True)  # os.path.join helps ensure this concatenation is OS independent\n",
    "    return df_concat\n",
    "\n",
    "## Import Dataset\n",
    "# import all scraped SF bay area rental listings data\n",
    "scraped_data_path = r\"D:\\\\Coding and Code projects\\\\Python\\\\craigslist_data_proj\\\\CraigslistWebScraper\\\\scraped_data\\\\sfbay\"\n",
    "\n",
    "df = recursively_import_all_CSV_and_concat_to_single_df(scraped_data_path)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get copy so we can test dataset without having to repeatedly re-load dataset\n",
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity check--after cleaning the city names, let's examine some of the cleaned data: Green Valley        1\n",
      "San Pablo           1\n",
      "Livermore           1\n",
      "Mariner's Island    1\n",
      "Pleasanton          1\n",
      "Martinez            1\n",
      "Portola Valley      1\n",
      "American Canyon     1\n",
      "Orinda              1\n",
      "Discovery Bay       1\n",
      "Name: cities, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Coding and Code projects\\Python\\craigslist_data_proj\\CraigslistWebScraper\\craigslist_venv\\lib\\site-packages\\ipykernel_launcher.py:18: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "d:\\Coding and Code projects\\Python\\craigslist_data_proj\\CraigslistWebScraper\\craigslist_venv\\lib\\site-packages\\ipykernel_launcher.py:24: FutureWarning: The default value of regex will change from True to False in a future version.\n"
     ]
    }
   ],
   "source": [
    "def clean_split_city_names(df, address_critera: list, neighborhood_criteria:list, split_city_delimiters: list, incorrect_city_names:dict, cities_not_in_region:dict, cities_that_need_extra_cleaning:dict):\n",
    "    \"\"\"Clean city names data in several ways:\n",
    "    a.) Remove extraneous address & neighborhood data placed in the city names HTML object, such as 'Rd', 'Blvd', or 'Downtown'.\n",
    "    b.) Unsplit city names data that are split via ',' & '/' delimiters.\n",
    "    c.) Replace abbreviated or mispelled city names, and remove city names that do not exist within the SF Bay Area (e.g., 'Redding').\n",
    "    d.) Remove any digits/integers within the city names data--ie, by using a '\\d+' regex as the argument of str.replace() and replace it with empty strings.\n",
    "    e.) Remove any city names records thast are left with merely empty strings (ie, the other steps removed all data for that given cities record).\n",
    "    f.) Remove any whitespace to avoid the same city names from being treated as different entities by Pandas, Python, or SQL. \n",
    "    g.) Use str.capwords() to capitalize words (ie, excluding apostrophes).\n",
    "    h.) Replace city names that are mispelled after having removed various street and neighborhood substrings such as 'St' or 'Ca'--e.g., '. Helena' should be 'St. Helena'. \"\"\"\n",
    "    # specify extraneous street & address data (e.g., 'Rd') that we want to remove from the city names column:\n",
    "    addr_criteria = '|'.join(address_critera) # Join pipe ('|') symbols to address list so we can str.split() on any one of these criteria (ie, 'or' condition splitting on each element separated by pipes):\n",
    "    # specify extraneous neighborhood criteria we should also remove from col\n",
    "    nbhood_criteria = '|'.join(neighborhood_criteria) # remove neighborhood names as well as state abbreviation (shown on website as 'Ca') that is shown without the usual comma delimiter!\n",
    "    # b.) specify delimiters we need to refer to un-split city names:\n",
    "    split_city_delimiters = '|'.join(split_city_delimiters) # join pipes to delimiters so we can use str.split() based on multiple 'or' criteria simultaneously\n",
    "    # clean city names data by removing extraneous address & neighborhood data, and unsplitting city names based on ',' & '\\' delimiters\n",
    "    df['cities'] =  df['cities'].str.split(addr_criteria).str[-1].str.replace(nbhood_criteria, '', case=True).str.lstrip()\n",
    "    df['cities'] = df['cities'].str.split(split_city_delimiters).str[0] #unsplit city names based on comma or forward-slash delimiters\n",
    "    # c.) replace specific abbreviated or mispelled city names, and remove cities that are not actually located in the sfbay region:\n",
    "    df = df.replace({'cities':incorrect_city_names}) # replace mispelled & abbreviated city names\n",
    "    df = df.replace({'cities':cities_not_in_region})  # remove (via empty string) cities that are not actually located in the sfbay region\n",
    "    # d.) Remove digits/integer-like data from cities column:\n",
    "    df['cities'] = df['cities'].str.replace('\\d+', '')  # remove any digits by using '/d+' regex to look up digits, and then replace with empty string\n",
    "    # e.) Remove any rows that have empty strings or null values for cities col (having performed the various data filtering and cleaning above)\n",
    "    df = df[df['cities'].str.strip().astype(bool)] # remove rows with empty strings (ie, '') for cities col \n",
    "    df = df.dropna(subset=['cities']) # remove any remaining 'cities' null records\n",
    "    # f.) Remove whitespace\n",
    "    df['cities'] = df['cities'].str.strip() \n",
    "    # g.) capitalize the city names using str.capwords() \n",
    "    df['cities'] = df['cities'].str.split().apply(lambda x: [val.capitalize() for val in x]).str.join(' ')\n",
    "    # h) Replace city names that are mispelled after having removed various street and neighborhood substrings such as 'St' or 'Ca'--e.g., '. Helena' should be 'St. Helena' & 'San los' should be 'San Carlos'. Also, remove any non-Bay Area cities such as Redding:\n",
    "    # df['cities'] = df['cities'].str.lower() # transform all records to lower-case, for ease of cleaning the data\n",
    "    df = df.replace({'cities':cities_that_need_extra_cleaning})\n",
    "    return df\n",
    "\n",
    "# specify various address and street name that we need to remove from the city names \n",
    "address_criteria = ['Boulevard', 'Blvd', 'Road', 'Rd', 'Avenue', 'Ave', 'Street', 'St', 'Drive', 'Dr', 'Real', 'E Hillsdale Blvd'] \n",
    "# specify various extraneous neighborhood names such as 'Downtown' \n",
    "neighborhood_criteria = ['Downtown', 'Central/Downtown', 'North', 'California', 'Ca.', 'Bay Area', 'St. Helena', 'St', 'nyon', \n",
    "'Jack London Square', 'Walking Distance To', 'El Camino', 'Mendocino County', 'San Mateo County', 'Alameda County', 'Rio Nido Nr', 'Mission Elementary', \n",
    "'Napa County', 'Golden Gate', 'Jennings', 'South Lake Tahoe', 'Tahoe Paradise', 'Kingswood Estates', 'South Bay', 'Skyline', 'San Antonio Tx', \n",
    "'East Bay', 'Morton Dr'] \n",
    "\n",
    "# specify what delimiters we want to search for to unsplit the split city names data:\n",
    "split_city_delimiters =  [',', '/']\n",
    "# specify dictionary of abbreviated & mispelled cities:\n",
    "incorrect_city_names = {'Rohnert Pk':'Rohnert Park', 'Hillsborough Ca': 'Hillsborough', 'South Sf': 'South San Francisco', 'Ca':'', 'East San Jose':'San Jose', 'Vallejo Ca':'Vallejo', 'Westgate On Saratoga .':'San Jose', 'Bodega':'Bodega Bay', 'Briarwood At Central Park':'Fremont', 'Campbell Ca':'Campbell', 'Almaden':'San Jose', '.':'', 'East Foothills':'San Jose', 'Lake County':'', 'Redwood Shores':'Redwood City'}\n",
    "\n",
    "# specify dictionary of cities that are not located in sfbay (ie, not located in the region):\n",
    "cities_not_in_region = {'Ketchum':'', 'Baypoinr':'', 'Quito': '', 'Redding':'', 'Bend' :''}\n",
    "\n",
    "# specify dictionary of city names that are mispelled after having removed various street and neighborhood substrings:\n",
    "cities_that_need_extra_cleaning = {'. Helena': 'St. Helena', '. Helena Deer Park': 'St. Helena', 'San Los':'San Carlos', 'Tro Valley':'Castro Valley', 'Rohnert Pk':'Rohnert Park',\n",
    "'Pbell':'Campbell', 'Pbell Ca':'Campbell', 'American Yon':'American Canyon'}\n",
    "\n",
    "# clean city names data:\n",
    "df1 = clean_split_city_names(df1, address_criteria, neighborhood_criteria, split_city_delimiters, incorrect_city_names, cities_not_in_region, cities_that_need_extra_cleaning)\n",
    "# sanity check\n",
    "print(f\"Sanity check--after cleaning the city names, let's examine some of the cleaned data: {df1.cities.value_counts().tail(10)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Coding and Code projects\\\\Python\\\\craigslist_data_proj\\\\CraigslistWebScraper\\\\Rentals'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to csv\n",
    "df1[['ids', 'cities']].to_csv('cleaned_cities_demo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_urls</th>\n",
       "      <th>ids</th>\n",
       "      <th>sqft</th>\n",
       "      <th>cities</th>\n",
       "      <th>prices</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>attr_vars</th>\n",
       "      <th>listing_descrip</th>\n",
       "      <th>date_of_webcrawler</th>\n",
       "      <th>...</th>\n",
       "      <th>is_furnished</th>\n",
       "      <th>attached_garage</th>\n",
       "      <th>detached_garage</th>\n",
       "      <th>carport</th>\n",
       "      <th>off_street_parking</th>\n",
       "      <th>no_parking</th>\n",
       "      <th>EV_charging</th>\n",
       "      <th>air_condition</th>\n",
       "      <th>no_smoking</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3523</th>\n",
       "      <td>https://sfbay.craigslist.org/eby/apa/d/concord...</td>\n",
       "      <td>7.408703e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>American Canyon</td>\n",
       "      <td>2,887</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>air conditioning\\nflooring: wood\\nfurnished\\na...</td>\n",
       "      <td>1 bedroom available in 2 story house in americ...</td>\n",
       "      <td>2021-11-28</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           listing_urls           ids  sqft  \\\n",
       "3523  https://sfbay.craigslist.org/eby/apa/d/concord...  7.408703e+09   NaN   \n",
       "\n",
       "               cities prices  bedrooms bathrooms  \\\n",
       "3523  American Canyon  2,887       1.0         1   \n",
       "\n",
       "                                              attr_vars  \\\n",
       "3523  air conditioning\\nflooring: wood\\nfurnished\\na...   \n",
       "\n",
       "                                        listing_descrip date_of_webcrawler  \\\n",
       "3523  1 bedroom available in 2 story house in americ...         2021-11-28   \n",
       "\n",
       "      ...  is_furnished attached_garage detached_garage carport  \\\n",
       "3523  ...             1               0               0       0   \n",
       "\n",
       "      off_street_parking  no_parking  EV_charging  air_condition  no_smoking  \\\n",
       "3523                   1           0            0              1           1   \n",
       "\n",
       "      Unnamed: 0  \n",
       "3523         NaN  \n",
       "\n",
       "[1 rows x 48 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['ids'] == 7408703227]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9245c747e8241d920f220897f12edbe786b61c4594b5fa55595ea3a9c3131f03"
  },
  "kernelspec": {
   "display_name": "Python 3.7.1 32-bit ('craigslist_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
