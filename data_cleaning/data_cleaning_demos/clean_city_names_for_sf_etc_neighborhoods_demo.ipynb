{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports-- file processing\n",
    "import datetime\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import datetime\n",
    "\n",
    "# data analysis libraries & SQL libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 758 entries, 0 to 757\n",
      "Data columns (total 47 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   listing_urls             758 non-null    object \n",
      " 1   ids                      751 non-null    float64\n",
      " 2   sqft                     488 non-null    float64\n",
      " 3   cities                   745 non-null    object \n",
      " 4   prices                   751 non-null    object \n",
      " 5   bedrooms                 745 non-null    float64\n",
      " 6   bathrooms                745 non-null    object \n",
      " 7   attr_vars                745 non-null    object \n",
      " 8   listing_descrip          745 non-null    object \n",
      " 9   date_of_webcrawler       751 non-null    object \n",
      " 10  kitchen                  745 non-null    float64\n",
      " 11  date_posted              745 non-null    object \n",
      " 12  region                   758 non-null    object \n",
      " 13  sub_region               758 non-null    object \n",
      " 14  cats_OK                  758 non-null    int64  \n",
      " 15  dogs_OK                  758 non-null    int64  \n",
      " 16  wheelchair_accessible    758 non-null    int64  \n",
      " 17  laundry_in_bldg          758 non-null    int64  \n",
      " 18  no_laundry               758 non-null    int64  \n",
      " 19  washer_and_dryer         758 non-null    int64  \n",
      " 20  washer_and_dryer_hookup  758 non-null    int64  \n",
      " 21  laundry_on_site          758 non-null    int64  \n",
      " 22  full_kitchen             758 non-null    int64  \n",
      " 23  dishwasher               758 non-null    int64  \n",
      " 24  refrigerator             758 non-null    int64  \n",
      " 25  oven                     758 non-null    int64  \n",
      " 26  flooring_carpet          758 non-null    int64  \n",
      " 27  flooring_wood            758 non-null    int64  \n",
      " 28  flooring_tile            758 non-null    int64  \n",
      " 29  flooring_hardwood        758 non-null    int64  \n",
      " 30  flooring_other           758 non-null    int64  \n",
      " 31  apt_type                 758 non-null    int64  \n",
      " 32  in_law_apt_type          758 non-null    int64  \n",
      " 33  condo_type               758 non-null    int64  \n",
      " 34  townhouse_type           758 non-null    int64  \n",
      " 35  cottage_or_cabin_type    758 non-null    int64  \n",
      " 36  single_fam_type          758 non-null    int64  \n",
      " 37  duplex_type              758 non-null    int64  \n",
      " 38  is_furnished             758 non-null    int64  \n",
      " 39  attached_garage          758 non-null    int64  \n",
      " 40  detached_garage          758 non-null    int64  \n",
      " 41  carport                  758 non-null    int64  \n",
      " 42  off_street_parking       758 non-null    int64  \n",
      " 43  no_parking               758 non-null    int64  \n",
      " 44  EV_charging              758 non-null    int64  \n",
      " 45  air_condition            758 non-null    int64  \n",
      " 46  no_smoking               758 non-null    int64  \n",
      "dtypes: float64(4), int64(33), object(10)\n",
      "memory usage: 278.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# import scraped  sfc data--ie, San Francisco rental listings data\n",
    "def recursively_import_all_CSV_and_concat_to_single_df(parent_direc, fn_regex=r'*.csv'):\n",
    "    \"\"\"Recursively search parent directory, and look up all CSV files.\n",
    "    Then, import all CSV files to a single Pandas' df using pd.concat()\"\"\"\n",
    "    path =  parent_direc # specify parent path of directories containing the scraped rental listings CSV data -- NB: use raw text--as in r'path...', or can we use the double-back slashes to escape back-slashes??\n",
    "    df_concat = pd.concat((pd.read_csv(file) for file in glob.iglob(\n",
    "        os.path.join(path, '**', fn_regex), \n",
    "        recursive=True)), ignore_index=True)  # os.path.join helps ensure this concatenation is OS independent\n",
    "    return df_concat\n",
    "\n",
    "\n",
    "# \n",
    "sf_scraped_direc = r'D:\\Coding and Code projects\\Python\\craigslist_data_proj\\CraigslistWebScraper\\scraped_data\\sfbay\\sfc'\n",
    "\n",
    "sf_data = recursively_import_all_CSV_and_concat_to_single_df(sf_scraped_direc)\n",
    "sf_data.info() # sanity check\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Downtown / Civic / Van Ness    87\n",
       "Soma / South Beach             86\n",
       "Mission District               59\n",
       "Lower Nob Hill                 32\n",
       "Sunset / Parkside              31\n",
       "                               ..\n",
       "Oakland, Ca                     1\n",
       "Mission                         1\n",
       "Sunnyside/Tahoe City            1\n",
       "South Lake Tahoe                1\n",
       "San Francico, Inner Sunset      1\n",
       "Name: cities, Length: 62, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf_data['cities'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 Soma \n",
       "1         Lower Pac Hts\n",
       "2      Mission District\n",
       "3               Sunset \n",
       "4          Lower Haight\n",
       "             ...       \n",
       "753                 NaN\n",
       "754                 NaN\n",
       "755                 NaN\n",
       "756                 NaN\n",
       "757                 NaN\n",
       "Name: cities, Length: 758, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf_data['cities'].str.split('/', expand = False).str[0]   # split cities based on presence of the forward-slash delimiter (ie: '/'), and then parse only the 1st such element. This way, we will have only the primary (first) city listed for each 'split' city name. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity check--there should now only be city names of 'San Francisco': San Francisco    669\n",
      "Name: cities, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kevin Allen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Kevin Allen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "C:\\Users\\Kevin Allen\\Anaconda3\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "C:\\Users\\Kevin Allen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# clean SF data--change neighborhood names to simply SF city name\n",
    "def clean_city_names_for_sf(list_of_sf_neighborhoods, df):\n",
    "    \"\"\"In sfbay craiglist listings,\n",
    "    the name of the 'small' span HTML object\n",
    "    --which contains the city names--shows the \n",
    "    names of SF neighborhoods instead of the city itself.\n",
    "    \n",
    "    Since we are only interested in city-level data,\n",
    "    not within-city data such as city neighborhoods,\n",
    "    we will replace any SF neighborhood names\n",
    "    with simply the name of the city (ie, San Francisco).\n",
    "    \n",
    "    Make a case-insensitive search, since we only care \n",
    "    about basic spellings of neighborhood names. Denote\n",
    "    any non-SF data as empty strings, and then remove \n",
    "    these records from dataset since we only want SF data.\"\"\"\n",
    "\n",
    "    sf_neighborhoods = list_of_sf_neighborhoods # input list of all neighborhoods in SF\n",
    "    # 1.) remove records that are missing city names from dataset\n",
    "    filtered_df = df.dropna(subset = ['cities'], how='any') # remove any records that are missing city names\n",
    "    #2.) split cities that are listed as having multiple city names with a slash delimiter (ie, '/'), and parse the first city name of each such row\n",
    "    filtered_df['cities'] = filtered_df['cities'].str.split('/', expand = False).str[0]   # split cities based on presence of the forward-slash delimiter (ie: '/'), and then parse only the 1st such element. This way, we will have only the primary (first) city listed for each 'split' city name. \n",
    "    \n",
    "    # 3.) use str.contains() to look up any neighborhoods that are located within SF, and use np.where() to replace the neighborhood names with simply the city name (ie, 'San Francisco'). NB: if no SF neighborhoods are found, then impute row as null using np.null.  \n",
    "    filtered_df['cities'] = pd.np.where(filtered_df['cities'].str.contains('|'.join(sf_neighborhoods), case=False), \"San Francisco\", '') # assign city name for any rows contain sf neighborhood names for the cities col\n",
    "    # 4.) Remove all of the rows with cities imputed as empty strings--ie, because they are not actually located within San Francisco\n",
    "    filtered_df_final = filtered_df[filtered_df['cities'].str.strip().astype(bool)]\n",
    "    return filtered_df_final\n",
    "\n",
    "\n",
    "# specify list of all sf neighborhoods\n",
    "sf_neighborhoods = [\n",
    "    'Anza Vista', 'Ashbury Heights', 'Ashbury Hts', 'Alamo Square'\n",
    "    'Balboa Hollow', 'Balboa Terrace', 'Bayview', 'Belden Place', 'Bernal Heights',\n",
    "    'Lower Pac Hts', 'Mission District', 'Lower Nob Hill', 'Downtown',\n",
    "    'Buena Vista', 'Butchertown (Old and New)','Castro', 'Cathedral Hill', 'Cayuga Terrace',\n",
    "    'China Basin','Chinatown', 'Civic Center','Clarendon Heights', 'Cole Valley',\n",
    "    'Corona Heights', 'Cow Hollow','Crocker-Amazon','Design District','Diamond Heights', 'Diamond Hts', 'Dogpatch',\n",
    "    'Dolores Heights', 'Duboce Triangle',' Embarcadero', 'Eureka Valley',\n",
    "    'Excelsior', 'Fillmore', 'Financial District', \"Fisherman's Wharf\", 'Forest Hill', 'Forest Knolls', 'Glen Park', 'Golden Gate Heights', \n",
    "    'Haight', 'Hayes Valley', 'Hunters Point', 'India Basin', 'Ingleside', 'Inner Sunset', 'Jackson Square', 'Japantown',\n",
    "    'Jordan Park', 'Laguna Honda', 'Lake Street', 'Lakeside', 'Lakeshore', 'Laurel Heights', 'Lincoln Manor', 'Little Hollywood', 'Little Russia',\n",
    "    'Little Saigon', 'Lone Mountain', ' Lower Haight', 'Lower Pacific Heights', 'Lower Pac Hts', 'Lower Nob Hill', ' Marina', 'Merced Heights', 'Merced Manor', 'Midtown Terrace',\n",
    "    'Mid-Market', 'Miraloma Park', 'Mission Bay', 'Mission', 'Mission Dolores', 'Mission Terrace', 'Monterey Heights', 'Mount Davidson',\n",
    "    'nob hill', 'Noe Valley', 'nopa', 'North Beach', 'Panhandle', 'Oceanview','Outer Mission', ' Outer Sunset', 'Pacific Heights', 'Parkmerced',\n",
    "    'Parkside', 'Parnassus', 'Polk Gulch', 'Portola', 'Portola Place', 'portola district'\n",
    "    'Potrero Hill', 'Presidio', 'Presidio Heights', 'Richmond', 'Richmond District', 'Rincon Hill', 'Russian Hill', 'Saint Francis Wood', 'Sea Cliff', \n",
    "    'Sherwood Forest', 'South Beach', 'Silver Terrace', 'South End', 'South of Market', 'soma', 'Sunnydale', 'Sunnyside', 'Sunset', \n",
    "    'Telegraph Hill', 'Tenderloin', 'Treasure Island', 'Twin Peaks','Union Square', 'University Mound',\n",
    "    'USF', 'Upper Market', 'Visitacion Valley', 'Vista del Mar', 'West Portal', 'Western Addition',\n",
    "    'Westwood Highlands', 'Westwood Park', 'Yerba Buena', 'SFSU', 'CCSF', 'Fort Mason', 'Laurel Hts', 'UCSF', 'San Francisco'\n",
    "    'Turk St', 'Showplace Square'\n",
    "    ]\n",
    "\n",
    "\n",
    "# re-label all SF neighborhoods as city name of SF, and remove all non-SF data:\n",
    "sf_data = clean_city_names_for_sf(sf_neighborhoods, sf_data)\n",
    "\n",
    "\n",
    "print(f\"Sanity check--there should now only be city names of 'San Francisco':\\n{sf_data['cities'].value_counts()}\") # sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace the existing 'sfc' Nov 19, 2021 CSV file since we scraped these 'sfc' data prior to having this function ready for deployment:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "San Francisco    669\n",
       "Name: cities, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace existing CSV file since we scraped these 'sfc' data prior to having this function ready for deployment:\n",
    "\n",
    "direc_for_csv = r'D:/Coding and Code projects/Python/craigslist_data_proj/craigslist_webscraper/scraped_data/sfbay/sfc/craigslist_rental_sfbay_sfc_11_19_2021.csv'\n",
    "\n",
    "sf_data.to_csv(direc_for_csv, index=False) # export\n",
    "# \"D:\\\\Coding and Code projects\\\\Python\\\\craigslist_data_proj\\\\craigslist_webscraper\\\\scraped_dat\\\\sfbay\\\\sfc\\\\craigslist_rental_sfbay_sfc_11_19_2021.csv\")\n",
    "\n",
    "# sanity check\n",
    "sf_data_cleaned = recursively_import_all_CSV_and_concat_to_single_df(sf_scraped_direc)\n",
    "\n",
    "sf_data_cleaned.cities.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next, clean the East Bay & South Bay data we've scraped prior to creating this data cleaning functions:\n",
    "\n",
    "### Let's start with South Bay data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                        listing_urls           ids    sqft  \\\n",
       " 0  https://sfbay.craigslist.org/sby/apa/d/sunnyva...  7.400518e+09   300.0   \n",
       " 1  https://sfbay.craigslist.org/sby/apa/d/palo-al...  7.400511e+09  1196.0   \n",
       " 2  https://sfbay.craigslist.org/sby/apa/d/sunnyva...  7.400505e+09   571.0   \n",
       " 3  https://sfbay.craigslist.org/sby/apa/d/san-jos...  7.400508e+09     NaN   \n",
       " 4  https://sfbay.craigslist.org/sby/apa/d/mountai...  7.400506e+09   750.0   \n",
       " \n",
       "            cities prices  bedrooms bathrooms  \\\n",
       " 0       Sunnyvale  2,100       0.0         1   \n",
       " 1  San Jose South  5,583       3.0         2   \n",
       " 2       Sunnyvale  2,665       0.0         1   \n",
       " 3  San Jose North  1,000       1.0    shared   \n",
       " 4   Mountain View  2,812       1.0         1   \n",
       " \n",
       "                                            attr_vars  \\\n",
       " 0  air conditioning\\ncats are OK - purrr\\ndogs ar...   \n",
       " 1  EV charging\\nair conditioning\\ncats are OK - p...   \n",
       " 2  EV charging\\nair conditioning\\ncats are OK - p...   \n",
       " 3  application fee details: Credit, background ch...   \n",
       " 4  cats are OK - purrr\\ndogs are OK - wooof\\nfloo...   \n",
       " \n",
       "                                      listing_descrip date_of_webcrawler  ...  \\\n",
       " 0  furnished studio - great monthly rates!\\ntake ...         2021-10-28  ...   \n",
       " 1  luxury apartments in mountain view\\n\\ncall: sh...         2021-10-28  ...   \n",
       " 2  new apartments in sunnyvale designed just for ...         2021-10-28  ...   \n",
       " 3  this is called a \"semi-studio\" since the room ...         2021-10-28  ...   \n",
       " 4  heatherstone: apartments in mountain view\\npla...         2021-10-28  ...   \n",
       " \n",
       "    duplex_type is_furnished attached_garage detached_garage  carport  \\\n",
       " 0            0            1               0               0        0   \n",
       " 1            0            0               0               1        0   \n",
       " 2            0            0               1               0        0   \n",
       " 3            0            0               0               0        0   \n",
       " 4            0            0               0               0        1   \n",
       " \n",
       "    off_street_parking  no_parking  EV_charging  air_condition  no_smoking  \n",
       " 0                   1           0            0              1           1  \n",
       " 1                   0           0            1              1           1  \n",
       " 2                   0           0            1              1           1  \n",
       " 3                   0           0            0              0           1  \n",
       " 4                   0           0            0              0           1  \n",
       " \n",
       " [5 rows x 47 columns],\n",
       "                                         listing_urls           ids    sqft  \\\n",
       " 0  https://sfbay.craigslist.org/sby/apa/d/san-jos...  7.407170e+09  1102.0   \n",
       " 1  https://sfbay.craigslist.org/sby/apa/d/morgan-...  7.407168e+09   701.0   \n",
       " 2  https://sfbay.craigslist.org/sby/apa/d/san-jos...  7.403089e+09   800.0   \n",
       " 3  https://sfbay.craigslist.org/sby/apa/d/morgan-...  7.407167e+09   701.0   \n",
       " 4  https://sfbay.craigslist.org/sby/apa/d/sunnyva...  7.407164e+09  1155.0   \n",
       " \n",
       "               cities prices  bedrooms bathrooms  \\\n",
       " 0  San Jose Downtown  2,947       2.0         2   \n",
       " 1        Morgan Hill  2,625       1.0         1   \n",
       " 2     San Jose South  2,450       1.0         1   \n",
       " 3        Morgan Hill  2,625       1.0         1   \n",
       " 4          Sunnyvale  3,634       2.0         2   \n",
       " \n",
       "                                            attr_vars  \\\n",
       " 0  air conditioning\\napplication fee details: $39...   \n",
       " 1  open house dates\\nsaturday 2021-11-13\\nsunday ...   \n",
       " 2  air conditioning\\ncats are OK - purrr\\ndogs ar...   \n",
       " 3  open house dates\\nfriday 2021-11-12\\nsaturday ...   \n",
       " 4  EV charging\\nair conditioning\\ncats are OK - p...   \n",
       " \n",
       "                                      listing_descrip date_of_webcrawler  ...  \\\n",
       " 0  to schedule a tour\\n\\nwe now book our tour app...         2021-11-12  ...   \n",
       " 1  16915 #150~ 1~bedroom/1bath apartment home at ...         2021-11-12  ...   \n",
       " 2  downtown san jose condo for rent!\\n\\nbeautiful...         2021-11-12  ...   \n",
       " 3  16915 #150~ 1~bedroom/1bath apartment home at ...         2021-11-12  ...   \n",
       " 4  new apartments in sunnyvale designed just for ...         2021-11-12  ...   \n",
       " \n",
       "    duplex_type is_furnished attached_garage detached_garage  carport  \\\n",
       " 0            0            0               1               0        0   \n",
       " 1            0            0               0               0        0   \n",
       " 2            0            0               1               0        0   \n",
       " 3            0            0               0               0        0   \n",
       " 4            0            0               1               0        0   \n",
       " \n",
       "    off_street_parking  no_parking  EV_charging  air_condition  no_smoking  \n",
       " 0                   0           0            0              1           1  \n",
       " 1                   0           0            0              0           0  \n",
       " 2                   0           0            0              1           0  \n",
       " 3                   0           0            0              0           0  \n",
       " 4                   0           0            1              1           1  \n",
       " \n",
       " [5 rows x 47 columns])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import South Bay data--Oct 2021 & mid-Nov 2021:\n",
    "import pandas as pd\n",
    "sby_Oct, sby_Nov = pd.read_csv('D:\\Coding and Code projects\\Python\\craigslist_data_proj\\craigslist_webscraper\\scraped_data\\sfbay\\sby\\craigslist_rental_sfbay_sby_10_28_2021.csv'), pd.read_csv('D:\\Coding and Code projects\\Python\\craigslist_data_proj\\craigslist_webscraper\\scraped_data\\sfbay\\sby\\craigslist_rental_sfbay_sby_11_12_2021.csv')\n",
    "\n",
    "# sanity check\n",
    "sby_Oct.head(), sby_Nov.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ipykernel_launcher:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "ipykernel_launcher:15: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "ipykernel_launcher:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "ipykernel_launcher:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "ipykernel_launcher:15: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "ipykernel_launcher:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "ipykernel_launcher:15: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "ipykernel_launcher:15: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n"
     ]
    }
   ],
   "source": [
    "# clean SJ or other city name data\n",
    "def clean_given_city_names_data(city_name, list_of_neighborhood_names, df):\n",
    "    \"\"\"In the craigslist listings, the name of the 'small' span HTML object\n",
    "    --which contains the city names--shows various names for regions of \n",
    "    cities such as San Jose, such as 'San Jose downtown', 'San Jose South', etc.\n",
    "\n",
    "    We will use str contains to look up the given city substring (e.g., 'San Jose'),\n",
    "    and replace these with simply the name of the city itself: ie, 'San Jose'.\"\"\"\n",
    "    # 1.) remove records that are missing city names from dataset\n",
    "    filtered_df = df.dropna(subset = ['cities'], how='any') # remove any records that are missing city names\n",
    "    #2.) split cities that are listed as having multiple city names with a slash delimiter (ie, '/'), and parse the first city name of each such row\n",
    "    filtered_df['cities'] = filtered_df['cities'].str.split('/', expand = False).str[0]   # split cities based on presence of the forward-slash delimiter (ie: '/'), and then parse only the 1st such element. This way, we will have only the primary (first) city listed for each 'split' city name. \n",
    "\n",
    "    # 3.) use str.contains() to look up city names with given neighborhood names. Replace these with simply the city name of 'San Jose'\n",
    "    filtered_df['cities'] =  pd.np.where(filtered_df['cities'].str.contains('|'.join(list_of_neighborhood_names), case=False), city_name, filtered_df['cities']) # assign city name for any rows containing given city neighborhood names, else simply leave row unchanged.     \n",
    "    return filtered_df\n",
    "\n",
    "\n",
    "# specify list of neighborhoods for South Bay data that we need to clean:\n",
    "sj_neighborhoods = ['San Jose', 'Cambrian' 'East Foothills', 'Evergreen']\n",
    "\n",
    "santa_clara_neighborhoods = ['Santa Clara', 'Willow Glen']\n",
    "\n",
    "# clean San Jose data-- for Oct & Nov data, respectively \n",
    "sby_Oct, sby_Nov = clean_given_city_names_data('San Jose', sj_neighborhoods, sby_Oct), clean_given_city_names_data('San Jose', sj_neighborhoods, sby_Nov)\n",
    "\n",
    "# clean Santa Clara data\n",
    "sby_Oct, sby_Nov = clean_given_city_names_data('Santa Clara', santa_clara_neighborhoods, sby_Oct), clean_given_city_names_data('Santa Clara', santa_clara_neighborhoods, sby_Nov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "San Jose             469\n",
       "Sunnyvale            166\n",
       "Cupertino            139\n",
       "Santa Clara          114\n",
       "Mountain View         84\n",
       "Campbell              44\n",
       "Milpitas              18\n",
       "Los Gatos             16\n",
       "Morgan Hill           14\n",
       "Hollister              6\n",
       "Gilroy                 5\n",
       "Saratoga               3\n",
       "El Sobrante, Ca        2\n",
       "Fremont                1\n",
       "Hercules               1\n",
       "San Juan Bautista      1\n",
       "East Foothills         1\n",
       "Name: cities, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sby_Oct.cities.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace existing CSV scraped files with cleaned variants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace existing CSV files for South Bay data:\n",
    "# Oct data\n",
    "sby_Oct.to_csv('D:\\Coding and Code projects\\Python\\craigslist_data_proj\\craigslist_webscraper\\scraped_data\\sfbay\\sby\\craigslist_rental_sfbay_sby_10_28_2021.csv')\n",
    " # Nov data\n",
    "sby_Nov.to_csv('D:\\Coding and Code projects\\Python\\craigslist_data_proj\\craigslist_webscraper\\scraped_data\\sfbay\\sby\\craigslist_rental_sfbay_sby_11_12_2021.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean East Bay data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                        listing_urls           ids   sqft  \\\n",
       " 0  https://sfbay.craigslist.org/eby/apa/d/berkele...  7.401006e+09    NaN   \n",
       " 1  https://sfbay.craigslist.org/eby/apa/d/san-ram...  7.401008e+09  898.0   \n",
       " 2  https://sfbay.craigslist.org/eby/apa/d/fremont...  7.401007e+09  615.0   \n",
       " 3  https://sfbay.craigslist.org/eby/apa/d/pleasan...  7.400999e+09    NaN   \n",
       " 4  https://sfbay.craigslist.org/eby/apa/d/oakland...  7.397958e+09  800.0   \n",
       " \n",
       "                             cities prices  bedrooms bathrooms  \\\n",
       " 0                         Berkeley  4,450       3.0         1   \n",
       " 1             Danville / San Ramon  2,676       1.0         1   \n",
       " 2    Fremont / Union City / Newark  2,013       1.0         1   \n",
       " 3  Dublin / Pleasanton / Livermore  2,850       0.0         1   \n",
       " 4     Oakland Lake Merritt / Grand  2,200       2.0         1   \n",
       " \n",
       "                                            attr_vars  \\\n",
       " 0  cats are OK - purrr\\nflooring: wood\\nfurnished...   \n",
       " 1  EV charging\\nair conditioning\\ncats are OK - p...   \n",
       " 2  cats are OK - purrr\\ndogs are OK - wooof\\nfloo...   \n",
       " 3  air conditioning\\ncats are OK - purrr\\ndogs ar...   \n",
       " 4  application fee details: $50\\nflooring: wood\\n...   \n",
       " \n",
       "                                      listing_descrip date_of_webcrawler  ...  \\\n",
       " 0  this a lovely townhouse 4 blocks away from ucb...         2021-10-29  ...   \n",
       " 1  b103 - beautiful spacious two bedrooms one-bat...         2021-10-29  ...   \n",
       " 2  your refuge~your retreat~your perfect home\\nth...         2021-10-29  ...   \n",
       " 3  furnished studio - great monthly rates!\\ntake ...         2021-10-29  ...   \n",
       " 4  2bedroom 1bath apt. available for moving now. ...         2021-10-29  ...   \n",
       " \n",
       "    duplex_type is_furnished attached_garage detached_garage  carport  \\\n",
       " 0            0            1               0               0        0   \n",
       " 1            0            0               0               0        1   \n",
       " 2            0            0               0               0        1   \n",
       " 3            0            1               0               0        0   \n",
       " 4            0            0               0               0        0   \n",
       " \n",
       "    off_street_parking  no_parking  EV_charging  air_condition  no_smoking  \n",
       " 0                   0           0            0              0           0  \n",
       " 1                   0           0            1              1           1  \n",
       " 2                   0           0            0              0           1  \n",
       " 3                   1           0            0              1           1  \n",
       " 4                   0           0            0              0           0  \n",
       " \n",
       " [5 rows x 47 columns],\n",
       "                                         listing_urls           ids    sqft  \\\n",
       " 0  https://sfbay.craigslist.org/eby/apa/d/fremont...  7.405360e+09   600.0   \n",
       " 1  https://sfbay.craigslist.org/eby/apa/d/oakland...  7.405370e+09   746.0   \n",
       " 2  https://sfbay.craigslist.org/eby/apa/d/oakland...  7.405370e+09   528.0   \n",
       " 3  https://sfbay.craigslist.org/eby/apa/d/pleasan...  7.405368e+09  1019.0   \n",
       " 4  https://sfbay.craigslist.org/eby/apa/d/tracy-b...  7.405365e+09  1601.0   \n",
       " \n",
       "                                cities prices  bedrooms bathrooms  \\\n",
       " 0       Fremont / Union City / Newark  2,279       1.0         1   \n",
       " 1        Oakland Lake Merritt / Grand  2,245       2.0         1   \n",
       " 2                    Oakland Downtown  1,645       1.0         1   \n",
       " 3  Concord / Pleasant Hill / Martinez  2,795       2.0         2   \n",
       " 4     Dublin / Pleasanton / Livermore  3,099       3.0       2.5   \n",
       " \n",
       "                                            attr_vars  \\\n",
       " 0  cats are OK - purrr\\ndogs are OK - wooof\\napar...   \n",
       " 1  cats are OK - purrr\\ndogs are OK - wooof\\nfloo...   \n",
       " 2  cats are OK - purrr\\ndogs are OK - wooof\\nfloo...   \n",
       " 3  air conditioning\\ncats are OK - purrr\\ndogs ar...   \n",
       " 4  EV charging\\nair conditioning\\ncats are OK - p...   \n",
       " \n",
       "                                      listing_descrip date_of_webcrawler  ...  \\\n",
       " 0  the woods\\n40640 high street\\nfremont, ca 9453...         2021-11-08  ...   \n",
       " 1  1511 jackson street #r31, oakland, ca\\n\\nopen ...         2021-11-08  ...   \n",
       " 2  one bedroom in pet-friendly building! 380 eucl...         2021-11-08  ...   \n",
       " 3  call us today show contact info\\n\\nwith vaulte...         2021-11-08  ...   \n",
       " 4  search no more! the perfect community does exi...         2021-11-08  ...   \n",
       " \n",
       "    duplex_type is_furnished attached_garage detached_garage  carport  \\\n",
       " 0            0            0               0               0        1   \n",
       " 1            0            0               0               0        0   \n",
       " 2            0            0               0               0        0   \n",
       " 3            0            0               0               1        0   \n",
       " 4            0            0               1               0        0   \n",
       " \n",
       "    off_street_parking  no_parking  EV_charging  air_condition  no_smoking  \n",
       " 0                   0           0            0              0           1  \n",
       " 1                   0           0            0              0           1  \n",
       " 2                   0           0            0              0           0  \n",
       " 3                   0           0            0              1           1  \n",
       " 4                   0           0            1              1           1  \n",
       " \n",
       " [5 rows x 47 columns],\n",
       "                                         listing_urls           ids    sqft  \\\n",
       " 0  https://sfbay.craigslist.org/eby/apa/d/oakland...  7.413537e+09  2634.0   \n",
       " 1  https://sfbay.craigslist.org/eby/apa/d/pittsbu...  7.402765e+09   500.0   \n",
       " 2  https://sfbay.craigslist.org/eby/apa/d/oakland...  7.413532e+09   550.0   \n",
       " 3  https://sfbay.craigslist.org/eby/apa/d/oakland...  7.413532e+09     NaN   \n",
       " 4  https://sfbay.craigslist.org/eby/apa/d/pittsbu...  7.413529e+09  3300.0   \n",
       " \n",
       "                                cities prices  bedrooms bathrooms  \\\n",
       " 0        Oakland Piedmont / Montclair  7,500       4.0         3   \n",
       " 1  Concord / Pleasant Hill / Martinez  1,350       1.0         1   \n",
       " 2        Oakland Lake Merritt / Grand  1,595       1.0         1   \n",
       " 3                        Oakland West  3,995       4.0         4   \n",
       " 4  Concord / Pleasant Hill / Martinez  4,100       5.0         3   \n",
       " \n",
       "                                            attr_vars  \\\n",
       " 0  flooring: wood\\nhouse\\nw/d in unit\\nno smoking...   \n",
       " 1  flooring: wood\\nfurnished\\ntownhouse\\nno laund...   \n",
       " 2  open house dates\\nsunday 2021-11-28\\nwednesday...   \n",
       " 3  open house dates\\nwednesday 2021-12-01\\nsaturd...   \n",
       " 4  open house dates\\nsaturday 2021-12-04\\nsunday ...   \n",
       " \n",
       "                                      listing_descrip date_of_webcrawler  ...  \\\n",
       " 0  this beautiful 2634+/- square foot tuscan/medi...         2021-11-28  ...   \n",
       " 1  nice townhouse style duplex with bonus room wh...         2021-11-28  ...   \n",
       " 2  $1595/mo.\\n2nd month is free when you sign a 1...         2021-11-28  ...   \n",
       " 3  shown wednesday 5pm!!\\nnew new new!! construct...         2021-11-28  ...   \n",
       " 4  5 large bedrooms 3 bath 3 car garage big back ...         2021-11-28  ...   \n",
       " \n",
       "    duplex_type is_furnished attached_garage detached_garage  carport  \\\n",
       " 0            0            0               0               0        0   \n",
       " 1            0            1               0               0        0   \n",
       " 2            0            0               0               0        0   \n",
       " 3            0            0               0               0        0   \n",
       " 4            0            0               0               0        0   \n",
       " \n",
       "    off_street_parking  no_parking  EV_charging  air_condition  no_smoking  \n",
       " 0                   1           0            0              0           1  \n",
       " 1                   1           0            0              0           1  \n",
       " 2                   0           0            0              0           0  \n",
       " 3                   0           0            0              0           0  \n",
       " 4                   0           0            0              0           0  \n",
       " \n",
       " [5 rows x 47 columns])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import East Bay data\n",
    "import pandas as pd\n",
    "eby_Oct = pd.read_csv('D:\\Coding and Code projects\\Python\\craigslist_data_proj\\craigslist_webscraper\\scraped_data\\sfbay\\eby\\craigslist_rental_sfbay_eby_10_29_2021.csv')\n",
    "\n",
    "eby_early_Nov = pd.read_csv('D:\\Coding and Code projects\\Python\\craigslist_data_proj\\craigslist_webscraper\\scraped_data\\sfbay\\eby\\craigslist_rental_sfbay_eby_11_08_2021.csv')\n",
    "\n",
    "eby_late_Nov = pd.read_csv('D:\\Coding and Code projects\\Python\\craigslist_data_proj\\craigslist_webscraper\\scraped_data\\sfbay\\eby\\craigslist_rental_sfbay_eby_11_28_2021.csv')\n",
    "\n",
    "# sanity checks\n",
    "eby_Oct.head(),  eby_early_Nov.head(), eby_late_Nov.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ipykernel_launcher:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "ipykernel_launcher:15: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "ipykernel_launcher:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "ipykernel_launcher:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "ipykernel_launcher:15: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "ipykernel_launcher:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "ipykernel_launcher:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "ipykernel_launcher:15: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "ipykernel_launcher:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "ipykernel_launcher:15: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "ipykernel_launcher:15: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "ipykernel_launcher:15: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "ipykernel_launcher:15: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "ipykernel_launcher:15: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "ipykernel_launcher:15: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "ipykernel_launcher:15: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "ipykernel_launcher:15: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "ipykernel_launcher:15: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Oakland                                261\n",
       "Dublin                                 159\n",
       "Concord                                123\n",
       "Hayward                                110\n",
       "Berkeley                               101\n",
       "Fremont                                 93\n",
       "Alameda                                 84\n",
       "Pittsburg                               80\n",
       "San Leandro                             55\n",
       "Walnut Creek                            51\n",
       "Hercules, Pinole, San Pablo, El Sob     44\n",
       "Danville                                36\n",
       "Lafayette                               28\n",
       "Vallejo                                 19\n",
       "Emeryville                              18\n",
       "Fairfield                               18\n",
       "Berkeley North                          16\n",
       "Albany                                  15\n",
       "Richmond                                15\n",
       "Brentwood                                9\n",
       "South Lake Tahoe                         5\n",
       "Albany                                   4\n",
       "Vallejo                                  3\n",
       "Briarwood At Central Park                2\n",
       "Hercules                                 2\n",
       "Green Valley                             1\n",
       "Westbrae                                 1\n",
       "Vallejo Ca                               1\n",
       "Pinole                                   1\n",
       "Jack London Square                       1\n",
       "Bend                                     1\n",
       "San Ramon                                1\n",
       "Elmwood                                  1\n",
       "Bay Area                                 1\n",
       "Rio Vista                                1\n",
       "El Sobrante                              1\n",
       "Name: cities, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean East Bay data:\n",
    "\n",
    "# specify lists of city & neighborhood names to look up: \n",
    "oakland_neighborhoods = ['Oakland', 'Lake Merritt']\n",
    "\n",
    "alameda_neighborhoods = ['Alameda']\n",
    "\n",
    "hayward_neighborhoods = ['Hayward']\n",
    "\n",
    "richmond_neighborhoods = ['Richmond']\n",
    "\n",
    "# clean Oakland data:\n",
    "eby_Oct,  eby_early_Nov, eby_late_Nov = clean_given_city_names_data('Oakland', oakland_neighborhoods, eby_Oct), clean_given_city_names_data('Oakland', oakland_neighborhoods, eby_early_Nov), clean_given_city_names_data('Oakland', oakland_neighborhoods, eby_late_Nov)\n",
    "\n",
    "# clean Alameda\n",
    "eby_Oct,  eby_early_Nov, eby_late_Nov = clean_given_city_names_data('Alameda', alameda_neighborhoods, eby_Oct), clean_given_city_names_data('Alameda', alameda_neighborhoods, eby_early_Nov), clean_given_city_names_data('Alameda', alameda_neighborhoods, eby_late_Nov)\n",
    "\n",
    "\n",
    "# clean Richmond\n",
    "eby_Oct,  eby_early_Nov, eby_late_Nov = clean_given_city_names_data('Richmond', richmond_neighborhoods, eby_Oct), clean_given_city_names_data('Richmond', richmond_neighborhoods, eby_early_Nov), clean_given_city_names_data('Richmond', richmond_neighborhoods, eby_late_Nov)\n",
    "\n",
    "# clean Hayward\n",
    "eby_Oct,  eby_early_Nov, eby_late_Nov = clean_given_city_names_data('Hayward ', hayward_neighborhoods, eby_Oct), clean_given_city_names_data('Hayward ', hayward_neighborhoods, eby_early_Nov), clean_given_city_names_data('Hayward ', hayward_neighborhoods, eby_late_Nov)\n",
    "\n",
    "# sanity check\n",
    "eby_Oct.cities.value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace CSV files with cleaned data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_csv_no_index(path_and_csv_file, df):\n",
    "    return df.to_csv(path_and_csv_file, index=False)\n",
    "\n",
    "# eby_Oct\n",
    "to_csv_no_index('D:\\Coding and Code projects\\Python\\craigslist_data_proj\\craigslist_webscraper\\scraped_data\\sfbay\\eby\\craigslist_rental_sfbay_eby_10_29_2021.csv', eby_Oct)\n",
    "eby_Oct.to_csv('D:\\Coding and Code projects\\Python\\craigslist_data_proj\\craigslist_webscraper\\scraped_data\\sfbay\\eby\\craigslist_rental_sfbay_eby_10_29_2021.csv', index=False)\n",
    "\n",
    "# ealy Nov\n",
    "to_csv_no_index('D:\\Coding and Code projects\\Python\\craigslist_data_proj\\craigslist_webscraper\\scraped_data\\sfbay\\eby\\craigslist_rental_sfbay_eby_11_08_2021.csv', eby_early_Nov)\n",
    "# late Nov\n",
    "to_csv_no_index('D:\\Coding and Code projects\\Python\\craigslist_data_proj\\craigslist_webscraper\\scraped_data\\sfbay\\eby\\craigslist_rental_sfbay_eby_11_28_2021.csv', eby_late_Nov)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "868f069ec03d251bf5304722b36a079032b062039e590e3d2c740be1c52152d4"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
